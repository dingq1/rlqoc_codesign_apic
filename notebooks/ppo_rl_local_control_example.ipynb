{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgJ8i71FwLer",
        "outputId": "e09063cc-c2a5-4814-c02e-89b6321695c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optax in /usr/local/lib/python3.11/dist-packages (0.2.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.11/dist-packages (2.5.0)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from optax) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.11/dist-packages (from optax) (0.1.88)\n",
            "Requirement already satisfied: jax>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from optax) (0.4.33)\n",
            "Requirement already satisfied: jaxlib>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from optax) (0.4.33)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from optax) (1.26.4)\n",
            "Requirement already satisfied: etils[epy] in /usr/local/lib/python3.11/dist-packages (from optax) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chex>=0.1.87->optax) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.27->optax) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.27->optax) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.27->optax) (1.13.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (3.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install optax pandas gymnasium torch stable-baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWkrt8sqwR_E"
      },
      "outputs": [],
      "source": [
        "import jax.numpy as jnp\n",
        "import jax.random as jrandom\n",
        "import jax.scipy.linalg as jla\n",
        "import jax\n",
        "import matplotlib.pyplot as plt\n",
        "from jax import vmap\n",
        "from jax import random\n",
        "import numpy as np\n",
        "import optax\n",
        "import time\n",
        "import pandas as pd\n",
        "from jax import grad\n",
        "import math\n",
        "import logging\n",
        "from collections import deque, defaultdict\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from typing import Optional\n",
        "\n",
        "import gymnasium as gym  # Updated import for Gymnasium\n",
        "from gymnasium import spaces\n",
        "import torch\n",
        "import torch.nn as nn  # Ensure nn is imported correctly\n",
        "from stable_baselines3.common.policies import ActorCriticPolicy\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "\n",
        "# ========================================\n",
        "# Logging Configuration\n",
        "# ========================================\n",
        "# ----- Logging Configuration (Print to Console) -----\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"  # Suppress TensorFlow/XLA logs\n",
        "\n",
        "# Create a logger and set level to INFO\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "# Remove any existing handlers\n",
        "if logger.hasHandlers():\n",
        "    logger.handlers.clear()\n",
        "\n",
        "# Create a stream handler that outputs to sys.stdout\n",
        "stream_handler = logging.StreamHandler(sys.stdout)\n",
        "stream_handler.setLevel(logging.INFO)\n",
        "\n",
        "# Create formatter and add it to the stream handler\n",
        "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "stream_handler.setFormatter(formatter)\n",
        "logger.addHandler(stream_handler)\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# Part 1: Control System Model (PIC + SLM)\n",
        "# ========================================\n",
        "\n",
        "# Constants and Parameters\n",
        "def calculate_Omega_rabi_prefactor(I_mW_per_cm2, Detuning_MHz):\n",
        "    \"\"\"\n",
        "    Calculate the effective Rabi frequency prefactor (MHz) based on laser intensity and detuning.\n",
        "\n",
        "    Parameters:\n",
        "    - I_mW_per_cm2: Laser intensity in mW/cm²\n",
        "    - Detuning_MHz: Detuning in MHz\n",
        "\n",
        "    Returns:\n",
        "    - Omega_effRabi_prefactor_MHz: Effective Rabi frequency prefactor in MHz\n",
        "    \"\"\"\n",
        "    hbar = 1.0545718e-34  # Reduced Planck constant (J·s)\n",
        "    c = 3e8  # Speed of light in vacuum (m/s)\n",
        "    epsilon_0 = 8.854187817e-12  # Permittivity of free space (F/m)\n",
        "    mu0e = 3.336e-29  # |0> <-> |e> (C·m)\n",
        "    mu1e = 3.400e-29  # |1> <-> |e> (C·m)\n",
        "\n",
        "    I = I_mW_per_cm2 * 10  # Convert intensity from mW/cm² to W/m²\n",
        "    E_0 = jnp.sqrt(2 * I / (c * epsilon_0))  # Electric field in V/m\n",
        "    Omega_0e_prefactor = (mu0e * E_0) / hbar\n",
        "    Omega_1e_prefactor = (mu1e * E_0) / hbar\n",
        "    Omega_effRabi_prefactor = (Omega_0e_prefactor * Omega_1e_prefactor) / (2 * Detuning_MHz * 1e6)\n",
        "    Omega_effRabi_prefactor_MHz = Omega_effRabi_prefactor / 1e6  # Convert to MHz\n",
        "    return Omega_effRabi_prefactor_MHz\n",
        "\n",
        "\n",
        "# Grid and atom positions\n",
        "def generate_grid(grid_size=600, grid_range=(-6, 6)):\n",
        "    \"\"\"\n",
        "    Generates a 2D grid using meshgrid for atom positioning.\n",
        "\n",
        "    Args:\n",
        "    grid_size (int): Number of points on the grid (default is 600).\n",
        "    grid_range (tuple): Range of x and y coordinates (default is (-6, 6)).\n",
        "\n",
        "    Returns:\n",
        "    X, Y: Meshgrid for the x and y coordinates.\n",
        "    \"\"\"\n",
        "    x = jnp.linspace(grid_range[0], grid_range[1], grid_size - 1)\n",
        "    y = jnp.linspace(grid_range[0], grid_range[1], grid_size - 1)\n",
        "    X, Y = jnp.meshgrid(x, y)\n",
        "    return X, Y\n",
        "\n",
        "# Function to generate atom positions\n",
        "def generate_atom_positions_equilateral(N_a, side_length=3.0, center=(0, 0), triangle_spacing_factor=2.0):\n",
        "    \"\"\"\n",
        "    Generate atom positions for any integer number of atoms (N_a) in equilateral triangular patterns.\n",
        "\n",
        "    Parameters:\n",
        "    - N_a (int): Total number of atoms.\n",
        "    - side_length (float): Length of each side of the equilateral triangle.\n",
        "    - center (tuple): Center of the first triangle (x_center, y_center).\n",
        "    - triangle_spacing_factor (float): Distance between triangle centers, as a multiple of side_length.\n",
        "\n",
        "    Returns:\n",
        "    - positions (list of tuples): List of (x, y) positions for the atoms.\n",
        "    \"\"\"\n",
        "    positions = []\n",
        "    x_center, y_center = center  # Center of the first triangle\n",
        "    height = (math.sqrt(3) / 2) * side_length  # Height of the equilateral triangle\n",
        "\n",
        "    # Generate complete triangles\n",
        "    num_full_triangles = N_a // 3\n",
        "    for triangle_idx in range(num_full_triangles):\n",
        "        # Calculate the center for the current triangle\n",
        "        current_x_center = x_center + triangle_idx * triangle_spacing_factor * side_length\n",
        "        current_y_center = y_center\n",
        "\n",
        "        # Place atoms at the corners of the equilateral triangle\n",
        "        positions.append((current_x_center - side_length / 2, current_y_center - height / 2))  # Bottom left\n",
        "        positions.append((current_x_center + side_length / 2, current_y_center - height / 2))  # Bottom right\n",
        "        positions.append((current_x_center, current_y_center + height / 2))  # Top vertex\n",
        "\n",
        "    # Place remaining atoms (if any)\n",
        "    remaining_atoms = N_a % 3\n",
        "    if remaining_atoms > 0:\n",
        "        # Get the last triangle's center\n",
        "        if num_full_triangles > 0:\n",
        "            last_x_center = x_center + (num_full_triangles - 1) * triangle_spacing_factor * side_length\n",
        "            last_y_center = y_center\n",
        "        else:\n",
        "            last_x_center = x_center\n",
        "            last_y_center = y_center\n",
        "\n",
        "        # Add remaining atoms sequentially around the last triangle\n",
        "        if remaining_atoms >= 1:\n",
        "            positions.append((last_x_center - side_length / 2, last_y_center - height / 2))  # Bottom left\n",
        "        if remaining_atoms == 2:\n",
        "            positions.append((last_x_center + side_length / 2, last_y_center - height / 2))  # Bottom right\n",
        "\n",
        "    return positions\n",
        "\n",
        "# Dipoles for each atom\n",
        "def generate_dipoles(N_a):\n",
        "    dipoles = [jnp.array([1.0, 0]) for _ in range(N_a)]\n",
        "    return dipoles\n",
        "\n",
        "# Function to generate SLM modulations\n",
        "def generate_slm_mod(N_slm):\n",
        "    phase_mod = jnp.zeros(N_slm)\n",
        "    amp_mod = jnp.ones(N_slm)\n",
        "    return phase_mod, amp_mod\n",
        "\n",
        "# Functions for crosstalk model setup (with fabrication variations considered)\n",
        "def generate_distances(num_channels, pitch, random_variation=0.0, seed=None):\n",
        "    \"\"\"\n",
        "    Generate pairwise distances for waveguides arranged in a linear layout with optional randomness.\n",
        "\n",
        "    Parameters:\n",
        "        num_channels (int): Number of waveguides.\n",
        "        pitch (float): Spacing between adjacent waveguides (µm).\n",
        "        random_variation (float): Maximum random variation (±) for distances.\n",
        "        seed (int or None): Seed for reproducibility of randomness.\n",
        "\n",
        "    Returns:\n",
        "        jax.numpy.array: Pairwise distances matrix (µm).\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    distances = np.zeros((num_channels, num_channels), dtype=np.float32)\n",
        "    for i in range(num_channels):\n",
        "        for j in range(num_channels):\n",
        "            if i != j:\n",
        "                # Add randomness to the calculated distance\n",
        "                base_distance = abs(i - j) * pitch\n",
        "                variation = np.random.uniform(-random_variation, random_variation)\n",
        "                distances[i, j] = base_distance + variation\n",
        "    return jnp.array(distances)\n",
        "\n",
        "def generate_coupling_lengths(num_channels, base_length, scaling_factor=1.0, random_variation=0.0, seed=None):\n",
        "    \"\"\"\n",
        "    Generate coupling lengths with optional randomness.\n",
        "\n",
        "    Parameters:\n",
        "        num_channels (int): Number of waveguides.\n",
        "        base_length (float): Base coupling length for adjacent waveguides (µm).\n",
        "        scaling_factor (float): Multiplier to scale coupling length with increasing separation.\n",
        "        random_variation (float): Maximum random variation (±) for coupling lengths.\n",
        "        seed (int or None): Seed for reproducibility of randomness.\n",
        "\n",
        "    Returns:\n",
        "        jax.numpy.array: Coupling lengths matrix (µm).\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    coupling_lengths = np.zeros((num_channels, num_channels), dtype=np.float32)\n",
        "    for i in range(num_channels):\n",
        "        for j in range(num_channels):\n",
        "            if i != j:\n",
        "                base_length_ij = base_length * (scaling_factor**abs(i - j))\n",
        "                variation = np.random.uniform(-random_variation, random_variation)\n",
        "                coupling_lengths[i, j] = base_length_ij + variation\n",
        "    return jnp.array(coupling_lengths)\n",
        "\n",
        "def generate_n_eff_list(num_channels, base_n_eff, random_variation=0.0, seed=None):\n",
        "    \"\"\"\n",
        "    Generate an array of effective refractive indices with optional randomness.\n",
        "\n",
        "    Parameters:\n",
        "        num_channels (int): Number of waveguides.\n",
        "        base_n_eff (float): Base effective refractive index for all waveguides.\n",
        "        random_variation (float): Maximum random variation (±) around the base value.\n",
        "        seed (int or None): Seed for reproducibility of randomness.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Array of effective refractive indices (n_eff_list).\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    variations = np.random.uniform(-random_variation, random_variation, num_channels)\n",
        "    n_eff_list = base_n_eff + variations\n",
        "    return jnp.array(n_eff_list)\n",
        "\n",
        "\n",
        "# 1.1 Control Signal Construction\n",
        "\n",
        "def construct_V_smooth_with_carrier(tmin, tmax, t_steps, voltage_levels, omega_0, phi=0, max_step=30):\n",
        "    \"\"\"\n",
        "    Constructs a time-dependent control signal with piecewise smooth voltage levels and a carrier frequency component.\n",
        "\n",
        "    Parameters:\n",
        "    - tmin (float): Start time.\n",
        "    - tmax (float): End time.\n",
        "    - t_steps (int): Number of time steps.\n",
        "    - voltage_levels (array): Voltage levels for each piece.\n",
        "    - omega_0 (float): Carrier angular frequency (rad/s).\n",
        "    - phi (float, optional): Initial phase of the carrier (radians). Default is 0.\n",
        "    - max_step (float, optional): Maximum allowed voltage change between consecutive pieces. Default is 30.\n",
        "\n",
        "    Returns:\n",
        "    - V_t (array): Time-dependent control voltage with carrier modulation.\n",
        "    \"\"\"\n",
        "    time_points = jnp.linspace(tmin, tmax, t_steps)\n",
        "    num_pieces = len(voltage_levels)\n",
        "    piece_duration = t_steps // num_pieces\n",
        "\n",
        "    # Ensure voltage_levels is a JAX array\n",
        "    voltage_levels = jnp.array(voltage_levels, dtype=jnp.float32)\n",
        "\n",
        "    V_piecewise = jnp.zeros_like(time_points)\n",
        "\n",
        "    for i in range(num_pieces):\n",
        "        if i > 0:\n",
        "            delta_V = voltage_levels[i] - voltage_levels[i - 1]\n",
        "            if jnp.abs(delta_V) > max_step:\n",
        "                # Limit the voltage change to max_step\n",
        "                voltage_levels = voltage_levels.at[i].set(\n",
        "                    voltage_levels[i - 1] + jnp.sign(delta_V) * max_step\n",
        "                )\n",
        "\n",
        "        start_idx = i * piece_duration\n",
        "        # Ensure the last piece covers any remaining time steps\n",
        "        end_idx = (i + 1) * piece_duration if i < num_pieces - 1 else t_steps\n",
        "        V_piecewise = V_piecewise.at[start_idx:end_idx].set(\n",
        "            jnp.full(end_idx - start_idx, voltage_levels[i])\n",
        "        )\n",
        "\n",
        "    # Carrier modulation\n",
        "    carrier = jnp.cos(omega_0 * time_points + phi)\n",
        "    V_t = V_piecewise * carrier\n",
        "\n",
        "    return V_t\n",
        "\n",
        "\n",
        "# 1.2 Unitary Matrix Construction\n",
        "def dn(V):\n",
        "    return 4e-5 * V\n",
        "\n",
        "def phi_func(L, n, dn_val, lambda_):\n",
        "    return 2 * jnp.pi * L * (n + dn_val) / lambda_\n",
        "\n",
        "def D_func(a, t_val, phi_val):\n",
        "    return jnp.exp(1j * jnp.pi) * (a - t_val * jnp.exp(-1j * phi_val)) / (1 - t_val * a * jnp.exp(-1j * phi_val))\n",
        "\n",
        "def U_drmzm_single_channel(V0, V1, L, n0, lambda_0, a0, t0, a1, t1, psi_0=0):\n",
        "    dn_0 = dn(V0)\n",
        "    dn_1 = dn(V1)\n",
        "    phi0 = phi_func(L, n0, dn_0, lambda_0)\n",
        "    phi1 = phi_func(L, n0, dn_1, lambda_0)\n",
        "\n",
        "    D_00 = D_func(a0, t0, phi0) * jnp.exp(psi_0)\n",
        "    D_11 = D_func(a1, t1, phi1)\n",
        "\n",
        "    U_drmzm_matrix = jnp.array([[D_00, jnp.zeros_like(D_00)], [jnp.zeros_like(D_11), D_11]])\n",
        "    U_bs = (1 / jnp.sqrt(2)) * jnp.array([[1, 1], [1, -1]])\n",
        "    U_total = jnp.dot(U_bs, jnp.dot(U_drmzm_matrix, U_bs))\n",
        "\n",
        "    return U_total\n",
        "\n",
        "# Add Crosstalk\n",
        "def U_drmzm_multi_channel(\n",
        "    V0_t_list, V1_t_list, L, n0, lambda_0, a0, t0, a1, t1,\n",
        "    N_ch, distances, coupling_lengths, n_eff_list, kappa0, alpha, enable_crosstalk=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Constructs the multi-channel unitary matrix with optional inter-channel coupling (amplitude and phase crosstalk).\n",
        "\n",
        "    Parameters:\n",
        "    V0_t_list, V1_t_list: Control voltages for each channel.\n",
        "    L, n0, lambda_0, a0, t0, a1, t1: Physical parameters of the system.\n",
        "    N_ch (int): Number of waveguides (channels).\n",
        "    distances (jax.numpy.array): Pairwise distances between channels (µm).\n",
        "    coupling_lengths (jax.numpy.array): Pairwise coupling lengths (µm).\n",
        "    n_eff_list (jax.numpy.array): Effective refractive indices for each waveguide.\n",
        "    kappa0 (float): Maximum coupling coefficient.\n",
        "    alpha (float): Decay rate of coupling with distance.\n",
        "    enable_crosstalk (bool): If False, disables all crosstalk and returns a diagonal matrix.\n",
        "\n",
        "    Returns:\n",
        "    U_multi_channel_with_ct: Combined unitary matrix including (or excluding) crosstalk effects.\n",
        "    \"\"\"\n",
        "    # Step 1: Construct U_multi_channel_no_ct (diagonal matrix without crosstalk)\n",
        "    U_multi_channel_no_ct = jnp.zeros((N_ch, N_ch), dtype=jnp.complex64)\n",
        "    for i in range(N_ch):\n",
        "        V0_t = V0_t_list[i]\n",
        "        V1_t = V1_t_list[i]\n",
        "        U_single_channel = U_drmzm_single_channel(V0_t, V1_t, L, n0, lambda_0, a0, t0, a1, t1)\n",
        "        U_multi_channel_no_ct = U_multi_channel_no_ct.at[i, i].set(U_single_channel[0, 0])\n",
        "\n",
        "    # If crosstalk is disabled, return the diagonal matrix only\n",
        "    if not enable_crosstalk:\n",
        "        return U_multi_channel_no_ct\n",
        "\n",
        "    # Step 2: Initialize crosstalk matrix\n",
        "    U_wg_coupling_ct = jnp.eye(N_ch, dtype=jnp.complex64)  # Identity matrix\n",
        "\n",
        "    # Wave vector (k = 2π / λ)\n",
        "    k = 2 * jnp.pi / lambda_0\n",
        "\n",
        "    def compute_transfer_matrix(L_val, beta_1, beta_2, kappa):\n",
        "        \"\"\"Compute transfer matrix for two coupled waveguides.\"\"\"\n",
        "        delta_beta = (beta_1 - beta_2) / 2.0\n",
        "        kappa_eff = jnp.sqrt(kappa**2 + delta_beta**2)  # Effective coupling coefficient\n",
        "        cos_term = jnp.cos(kappa_eff * L_val)\n",
        "        sin_term = jnp.sin(kappa_eff * L_val)\n",
        "        delta_term = delta_beta / kappa_eff if kappa_eff != 0 else 0\n",
        "\n",
        "        return jnp.array([\n",
        "            [cos_term - 1j * delta_term * sin_term, -1j * sin_term],\n",
        "            [-1j * sin_term, cos_term + 1j * delta_term * sin_term]\n",
        "        ])\n",
        "\n",
        "    # Step 3: Compute direct coupling contributions\n",
        "    for i in range(N_ch):\n",
        "        beta_i = k * n_eff_list[i]\n",
        "        for j in range(i + 1, N_ch):  # Upper triangle only\n",
        "            beta_j = k * n_eff_list[j]\n",
        "\n",
        "            if distances[i, j] > 0:\n",
        "                # Compute coupling coefficient and propagation length\n",
        "                kappa_ij = kappa0 * jnp.exp(-alpha * distances[i, j])\n",
        "                L_ij = coupling_lengths[i, j]\n",
        "\n",
        "                # Compute transfer matrix\n",
        "                M = compute_transfer_matrix(L_ij, beta_i, beta_j, kappa_ij)\n",
        "\n",
        "                # Update crosstalk matrix with amplitude and phase contributions\n",
        "                U_wg_coupling_ct = U_wg_coupling_ct.at[i, j].set(M[0, 1])\n",
        "                U_wg_coupling_ct = U_wg_coupling_ct.at[j, i].set(jnp.conj(M[0, 1]))\n",
        "\n",
        "    # Step 4: Calculate combined matrix with crosstalk\n",
        "    U_multi_channel_with_ct = jnp.matmul(U_multi_channel_no_ct, U_wg_coupling_ct)\n",
        "\n",
        "    return U_multi_channel_with_ct\n",
        "\n",
        "# 1.3 SLM and Scattering Matrices\n",
        "def construct_U_multi_channel_slm(N_slm, phase_mod, amp_mod, t_steps):\n",
        "    U_slm = jnp.zeros((t_steps, N_slm, N_slm), dtype=jnp.complex64)\n",
        "    for t in range(t_steps):\n",
        "        for i in range(N_slm):\n",
        "            phase = jnp.exp(1j * phase_mod[i])\n",
        "            amplitude = amp_mod[i]\n",
        "            U_slm = U_slm.at[t, i, i].set(amplitude * phase)\n",
        "    return U_slm\n",
        "\n",
        "def construct_I_prime(N_scat, delta, t_steps):\n",
        "    I_prime = jnp.zeros((t_steps, N_scat, N_scat), dtype=jnp.complex64)\n",
        "    for t in range(t_steps):\n",
        "        I_prime = I_prime.at[t].set(jnp.eye(N_scat) + jnp.diag(jnp.full(N_scat, delta)))\n",
        "    return I_prime\n",
        "\n",
        "# 1.4 E-field Calculations\n",
        "def lg00_mode_profile(X, Y, beam_center, beam_waist):\n",
        "    cx, cy = beam_center\n",
        "    r_squared = (X - cx)**2 + (Y - cy)**2\n",
        "    E_profile = jnp.exp(-r_squared / (2 * beam_waist**2))\n",
        "    return E_profile\n",
        "\n",
        "def compute_E_field_for_channel(X, Y, E_t, beam_center, beam_waist, t_idx):\n",
        "    E_profile = lg00_mode_profile(X, Y, beam_center, beam_waist)\n",
        "    E_field = E_profile * (jnp.real(E_t) + 1j * jnp.imag(E_t))  # Corrected indexing\n",
        "    return E_field\n",
        "\n",
        "def compute_total_E_field_profile(X, Y, b_slm_out, beam_centers, beam_waist):\n",
        "    E_field_profiles = []\n",
        "    for t_idx in range(b_slm_out.shape[0]):\n",
        "        E_field_total = jnp.zeros_like(X, dtype=jnp.complex64)\n",
        "        for atom_index, beam_center in enumerate(beam_centers):\n",
        "            E_field_total += compute_E_field_for_channel(X, Y, b_slm_out[t_idx, atom_index], beam_center, beam_waist, t_idx)\n",
        "        E_field_profiles.append(E_field_total)\n",
        "    return jnp.array(E_field_profiles)\n",
        "\n",
        "def extract_E_field_at_atoms(E_field_profiles, atom_positions, X, Y):\n",
        "    E_field_at_atoms = []\n",
        "\n",
        "    for t_idx in range(E_field_profiles.shape[0]):\n",
        "        E_field_at_timestep = []\n",
        "        for x0, y0 in atom_positions:\n",
        "            x_idx = jnp.argmin(jnp.abs(X[0, :] - x0))\n",
        "            y_idx = jnp.argmin(jnp.abs(Y[:, 0] - y0))\n",
        "            E_field_at_timestep.append(E_field_profiles[t_idx][y_idx, x_idx])\n",
        "        E_field_at_atoms.append(jnp.array(E_field_at_timestep))\n",
        "    return jnp.array(E_field_at_atoms)\n",
        "\n",
        "def compute_alpha_t(E_fields_at_atoms, dipoles, Omega_prefactor_MHz):\n",
        "    alpha_t = []\n",
        "    for t_idx in range(E_fields_at_atoms.shape[0]):\n",
        "        alpha_t_timestep = []\n",
        "        for atom_idx in range(len(dipoles)):\n",
        "            E_field_atom = E_fields_at_atoms[t_idx, atom_idx]\n",
        "            dipole = dipoles[atom_idx]\n",
        "            alpha_t_timestep.append(Omega_prefactor_MHz * dipole[0] * E_field_atom)\n",
        "        alpha_t.append(jnp.array(alpha_t_timestep))\n",
        "    return jnp.array(alpha_t)\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# Part 2: Atomic Model\n",
        "# ========================================\n",
        "\n",
        "# Two levels per qubit\n",
        "N_qubit_level = 2\n",
        "\n",
        "# Define multi-qubit operators and Hamiltonians (as described previously)\n",
        "s_plus = jnp.array([[0, 1], [0, 0]], dtype=jnp.complex64)\n",
        "s_minus = jnp.array([[0, 0], [1, 0]], dtype=jnp.complex64)\n",
        "s_z = jnp.array([[1, 0], [0, -1]], dtype=jnp.complex64)\n",
        "\n",
        "def construct_multi_qubit_operator(single_qubit_op, N_a, N_qubit_level, qubit_idx):\n",
        "    I = jnp.eye(N_qubit_level, dtype=jnp.complex64)\n",
        "    op_list = [I] * N_a\n",
        "    op_list[qubit_idx] = single_qubit_op\n",
        "\n",
        "    multi_qubit_op = op_list[0]\n",
        "    for op in op_list[1:]:\n",
        "        multi_qubit_op = jnp.kron(multi_qubit_op, op)\n",
        "\n",
        "    return multi_qubit_op\n",
        "\n",
        "# Creation and annihilation operators for the quantized field (Fock mode)\n",
        "def construct_annihilation_operator(fock_dim):\n",
        "    a = jnp.zeros((fock_dim, fock_dim), dtype=jnp.complex64)\n",
        "    for n in range(1, fock_dim):\n",
        "        a = a.at[n - 1, n].set(jnp.sqrt(n))\n",
        "    a_dag = a.T.conj()  # Creation operator is the Hermitian conjugate of annihilation operator\n",
        "    return a, a_dag\n",
        "\n",
        "# Fock space dimensions\n",
        "fock_dim = 5\n",
        "a, a_dag = construct_annihilation_operator(fock_dim)\n",
        "I_fock = jnp.eye(fock_dim, dtype=jnp.complex64)\n",
        "\n",
        "# Drift Hamiltonian (H_0)\n",
        "def construct_H_0(N_a, omega_0, omega_r):  # omega_0/r in MHz\n",
        "    H_0_qubits = sum(0.5 * omega_0 * construct_multi_qubit_operator(s_z, N_a, 2, i) for i in range(N_a))\n",
        "    H_0_field = omega_r * jnp.kron(jnp.eye(2 ** N_a), a_dag @ a)\n",
        "    return jnp.kron(H_0_qubits, I_fock) + H_0_field\n",
        "\n",
        "# Control Hamiltonian\n",
        "def construct_H_control(N_a, N_qubit_level, g_real_t, g_imag_t):\n",
        "    H_control = jnp.zeros((N_qubit_level ** N_a * fock_dim, N_qubit_level ** N_a * fock_dim), dtype=jnp.complex64)\n",
        "    for i in range(N_a):\n",
        "        H_control += g_real_t[i] * (jnp.kron(construct_multi_qubit_operator(s_plus, N_a, N_qubit_level, i), a) +\n",
        "                                    jnp.kron(construct_multi_qubit_operator(s_minus, N_a, N_qubit_level, i), a_dag))\n",
        "        H_control += g_imag_t[i] * (1j * jnp.kron(construct_multi_qubit_operator(s_plus, N_a, N_qubit_level, i), a) -\n",
        "                                    1j * jnp.kron(construct_multi_qubit_operator(s_minus, N_a, N_qubit_level, i), a_dag))\n",
        "    return H_control\n",
        "\n",
        "# Time Evolution Hamiltonian (H(t))\n",
        "def construct_H_time(N_a, N_qubit_level, omega_0, omega_r, g_real_t, g_imag_t,\n",
        "                   atom_positions, gate_type='single'):\n",
        "    \"\"\"Construct the time-dependent Hamiltonian H(t) as a JAX array.\"\"\"\n",
        "    H_t_list = []  # Store Hamiltonians for each time step\n",
        "\n",
        "    # Construct base Hamiltonians\n",
        "    H_0 = construct_H_0(N_a, omega_0, omega_r)\n",
        "\n",
        "    # Construct H(t) for each time step\n",
        "    for t in range(len(g_real_t)):\n",
        "        H_control = construct_H_control(N_a, N_qubit_level, g_real_t[t], g_imag_t[t])\n",
        "        H_t = H_0 + H_control\n",
        "        H_t_list.append(H_t)\n",
        "\n",
        "    # Convert list of Hamiltonians to a JAX array\n",
        "    return jnp.array(H_t_list)\n",
        "\n",
        "# Compute accumulated propagator (U(t)) over time\n",
        "def compute_accumulated_propagator(H_t, dt, N_a, N_qubit_level):\n",
        "    dim = N_qubit_level ** N_a * fock_dim\n",
        "    U_accumulated = jnp.eye(dim, dtype=jnp.complex64)\n",
        "    U_t_all = []\n",
        "    for H in H_t:\n",
        "        U_t = jla.expm(-1j * H * dt)\n",
        "        U_accumulated = U_t @ U_accumulated\n",
        "        U_t_all.append(U_accumulated)\n",
        "    return jnp.array(U_t_all)\n",
        "\n",
        "# Trace out field from unitary matrix\n",
        "def trace_out_field_from_unitary(U_t, N_a, N_qubit_level, field_dim=5):\n",
        "    dim_qubits = N_qubit_level ** N_a\n",
        "    U_t_reshaped = U_t.reshape(dim_qubits, field_dim, dim_qubits, field_dim)\n",
        "    U_t_traced = jnp.sum(U_t_reshaped, axis=(1, 3))\n",
        "    return U_t_traced\n",
        "\n",
        "def trace_out_field_from_unitary_t_all(U_t_all, N_a, N_qubit_level, field_dim=5):\n",
        "    \"\"\"\n",
        "    Trace out the field from the unitary evolution matrix for all time steps.\n",
        "\n",
        "    Parameters:\n",
        "    - U_t_all: Time series of unitary matrices with shape (time_steps, dim_total, dim_total),\n",
        "      where dim_total = dim_qubits * field_dim.\n",
        "    - N_a: Number of atoms (qubits).\n",
        "    - N_qubit_level: Number of levels per qubit (typically 2).\n",
        "    - field_dim: Dimension of the field Hilbert space.\n",
        "\n",
        "    Returns:\n",
        "    - U_t_traced_all: Time series of unitary matrices with field traced out, shape (time_steps, dim_qubits, dim_qubits).\n",
        "    \"\"\"\n",
        "    time_steps = U_t_all.shape[0]\n",
        "    dim_qubits = N_qubit_level**N_a\n",
        "    total_dim = U_t_all.shape[-1]\n",
        "\n",
        "    # Ensure dimensions match\n",
        "    assert dim_qubits * field_dim == total_dim, \"Mismatch in total dimensions!\"\n",
        "\n",
        "    # Reshape to separate qubit and field dimensions\n",
        "    U_t_reshaped = U_t_all.reshape(time_steps, dim_qubits, field_dim, dim_qubits, field_dim)\n",
        "\n",
        "    # Trace out field dimensions\n",
        "    U_t_traced_all = jnp.sum(U_t_reshaped, axis=(2, 4))  # Sum over field dimensions\n",
        "\n",
        "    return U_t_traced_all\n",
        "\n",
        "# Fidelity Calculation\n",
        "def compute_fidelity_unitary(U_t_traced, U_target):\n",
        "    \"\"\"\n",
        "    Computes the fidelity of the unitary evolution compared to the target unitary\n",
        "    using the standard multi-qubit gate fidelity formula.\n",
        "\n",
        "    Parameters:\n",
        "    - U_t_traced: Reduced unitary matrix for the qubit system after tracing out the field.\n",
        "    - U_target: Target unitary matrix.\n",
        "\n",
        "    Returns:\n",
        "    - fidelity: The fidelity between the evolved and target unitary matrices.\n",
        "    \"\"\"\n",
        "    # Dimension of the Hilbert space\n",
        "    d = U_target.shape[0]  # For N qubits, d = 2^N\n",
        "\n",
        "    # Compute fidelity using the standard formula\n",
        "    trace_overlap = jnp.abs(jnp.trace(U_target.conj().T @ U_t_traced))**2\n",
        "    fidelity = trace_overlap / (d**2)\n",
        "\n",
        "    return jnp.real(fidelity)\n",
        "\n",
        "# record F(t)\n",
        "def compute_fidelity_unitary_t_all(U_t_traced_all, U_target):\n",
        "    \"\"\"\n",
        "    Computes the fidelity of the unitary evolution for all time steps\n",
        "    compared to the target unitary using the standard multi-qubit gate fidelity formula.\n",
        "\n",
        "    Parameters:\n",
        "    - U_t_traced_all: A list or array of reduced unitary matrices for the qubit system at all time steps.\n",
        "    - U_target: Target unitary matrix.\n",
        "\n",
        "    Returns:\n",
        "    - fidelity_all: Array of fidelities at each time step.\n",
        "    \"\"\"\n",
        "    # Dimension of the Hilbert space\n",
        "    d = U_target.shape[0]  # For N qubits, d = 2^N\n",
        "\n",
        "    def fidelity_at_timestep(U_t_traced):\n",
        "        trace_overlap = jnp.abs(jnp.trace(U_target.conj().T @ U_t_traced))**2\n",
        "        return trace_overlap / (d**2)\n",
        "\n",
        "    # Vectorized computation of fidelity for all time steps\n",
        "    fidelity_all = jax.vmap(fidelity_at_timestep)(U_t_traced_all)\n",
        "    return fidelity_all\n",
        "\n",
        "\n",
        "# Clifford gates\n",
        "def clifford_group_and_t_gate():\n",
        "    \"\"\"\n",
        "    Constructs the single-qubit Clifford group and includes the T gate.\n",
        "\n",
        "    Returns:\n",
        "    - clifford_group: List of tuples containing the gate name and matrix.\n",
        "    \"\"\"\n",
        "    # Define single-qubit gates\n",
        "    I = jnp.array([[1, 0], [0, 1]], dtype=jnp.complex64)  # Identity\n",
        "    H = (1 / jnp.sqrt(2)) * jnp.array([[1, 1], [1, -1]], dtype=jnp.complex64)  # Hadamard\n",
        "    S = jnp.array([[1, 0], [0, 1j]], dtype=jnp.complex64)  # Phase gate\n",
        "    X = jnp.array([[0, 1], [1, 0]], dtype=jnp.complex64)  # Pauli-X\n",
        "    Y = jnp.array([[0, -1j], [1j, 0]], dtype=jnp.complex64)  # Pauli-Y\n",
        "    Z = jnp.array([[1, 0], [0, -1]], dtype=jnp.complex64)  # Pauli-Z\n",
        "    T = jnp.array([[1, 0], [0, jnp.exp(1j * jnp.pi / 4)]], dtype=jnp.complex64)  # T gate (π/8 rotation)\n",
        "\n",
        "    # Clifford group: combinations of I, H, S, X, Y, Z\n",
        "    # The single-qubit Clifford group consists of 24 elements.\n",
        "    clifford_group = [\n",
        "        (\"X\", X),\n",
        "        (\"I\", I),\n",
        "        (\"H\", H),\n",
        "        (\"S\", S),\n",
        "        (\"Y\", Y),\n",
        "        (\"Z\", Z),\n",
        "        (\"HS\", H @ S),\n",
        "        (\"SH\", S @ H),\n",
        "        (\"HX\", H @ X),\n",
        "        (\"SX\", S @ X),\n",
        "        (\"SY\", S @ Y),\n",
        "        (\"SZ\", S @ Z),\n",
        "        (\"XH\", X @ H),\n",
        "        (\"YH\", Y @ H),\n",
        "        (\"ZH\", Z @ H),\n",
        "        (\"XS\", X @ S),\n",
        "        (\"YS\", Y @ S),\n",
        "        (\"ZS\", Z @ S),\n",
        "        (\"HSX\", H @ S @ X),\n",
        "        (\"HSY\", H @ S @ Y),\n",
        "        (\"HSZ\", H @ S @ Z),\n",
        "        (\"XHS\", X @ H @ S),\n",
        "        (\"YHS\", Y @ H @ S),\n",
        "        (\"ZHS\", Z @ H @ S),\n",
        "    ]\n",
        "\n",
        "    # Include T gate for extended functionality\n",
        "    clifford_group_with_t = clifford_group + [(\"T\", T)]\n",
        "\n",
        "    return clifford_group_with_t\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# Part 3: Function to Compute Gate Fidelity\n",
        "# ========================================\n",
        "\n",
        "def compute_multi_qubit_fidelity_closed_system(\n",
        "    V0_t_list, V1_t_list, L, n0, lambda_0, a0, t0, a1, t1, phase_mod, amp_mod, delta,\n",
        "    atom_positions, dipoles, beam_centers, beam_waist, X, Y, Omega_prefactor_MHz,\n",
        "    t_steps, dt,\n",
        "    N_ch, distances, coupling_lengths, n_eff_list, kappa0, alpha, enable_crosstalk,\n",
        "    N_slm, N_ch_slm_in, N_scat_1, N_scat_2, N_a, N_qubit_level, omega_0, omega_r, a_pic, a_scat_1,\n",
        "    U_target, gate_type='single'\n",
        "):\n",
        "    \"\"\"\n",
        "    Computes the multi-qubit fidelity for a closed system with a fixed tmax.\n",
        "\n",
        "    Parameters:\n",
        "        V0_t_list, V1_t_list: Control voltage time-series for each channel.\n",
        "        L, n0, lambda_0, a0, t0, a1, t1: Physical parameters of the MZM.\n",
        "        phase_mod, amp_mod: Phase and amplitude modulation parameters.\n",
        "        delta: Detuning.\n",
        "        atom_positions, dipoles: Atom positions and dipole moments.\n",
        "        beam_centers, beam_waist: Parameters of the spatial light modulator (SLM).\n",
        "        X, Y: 2D grid for the beam field.\n",
        "        Omega_prefactor_MHz: Prefactor for Rabi frequency in MHz.\n",
        "        t_steps, dt: Time parameters.\n",
        "        N_ch: Number of photonic channels.\n",
        "        distances: Pairwise distances between channels (µm).\n",
        "        coupling_lengths: Pairwise coupling lengths (µm).\n",
        "        n_eff_list: Effective refractive indices for the waveguides.\n",
        "        kappa0, alpha: Crosstalk parameters.\n",
        "        enable_crosstalk (bool): If False, crosstalk is disabled.\n",
        "        N_slm, N_ch_slm_in, N_scat_1, N_scat_2, N_a, N_qubit_level: System configuration.\n",
        "        omega_0, omega_r: Frequencies in MHz.\n",
        "        a_pic, a_scat_1: Initial fields.\n",
        "        U_target: Target unitary matrix.\n",
        "        gate_type: Type of quantum gate ('single', 'multi', etc.).\n",
        "\n",
        "    Returns:\n",
        "        Fidelity of the computed unitary matrix with respect to the target matrix.\n",
        "    \"\"\"\n",
        "    # Compute Unitary Matrix for Multi-Channel System\n",
        "    U_system_multi_channel = jnp.array([\n",
        "        U_drmzm_multi_channel(\n",
        "            [V0_t[i] for V0_t in V0_t_list],\n",
        "            [V1_t[i] for V1_t in V1_t_list],\n",
        "            L, n0, lambda_0, a0, t0, a1, t1,\n",
        "            N_ch, distances, coupling_lengths, n_eff_list,\n",
        "            kappa0, alpha, enable_crosstalk\n",
        "        )\n",
        "        for i in range(t_steps)\n",
        "    ])\n",
        "\n",
        "    # Compute scattering and SLM matrices\n",
        "    I1_prime = construct_I_prime(N_scat_1, delta, t_steps)\n",
        "    U_tensor_product = jnp.array([jnp.kron(U_system_multi_channel[i], I1_prime[i]) for i in range(t_steps)])\n",
        "\n",
        "    # Output modes calculations\n",
        "    a_total = jnp.kron(a_pic, a_scat_1)\n",
        "    output_modes = jnp.array([jnp.dot(U_tensor_product[i], a_total) for i in range(t_steps)])\n",
        "    output_modes_reshaped = output_modes.reshape(t_steps, N_ch, N_scat_1)\n",
        "    a_pic_out = jnp.sum(output_modes_reshaped, axis=-1)\n",
        "    a_scat_1_out = jnp.sum(output_modes_reshaped, axis=-2)\n",
        "\n",
        "    # Compute final output modes after SLM and second scattering\n",
        "    b_slm_in = jnp.zeros((t_steps, N_slm), dtype=jnp.complex64)\n",
        "    b_scat2_in = jnp.zeros((t_steps, N_scat_2), dtype=jnp.complex64)\n",
        "\n",
        "    for t in range(t_steps):\n",
        "        b_slm_in = b_slm_in.at[t, :N_ch_slm_in].set(a_pic_out[t, :N_ch_slm_in])\n",
        "        b_slm_in = b_slm_in.at[t, N_ch_slm_in:].set(a_scat_1_out[t, :(N_slm - N_ch_slm_in)])\n",
        "\n",
        "        b_scat2_in = b_scat2_in.at[t, :(N_ch - N_ch_slm_in)].set(a_pic_out[t, N_ch_slm_in:])\n",
        "        b_scat2_in = b_scat2_in.at[t, (N_ch - N_ch_slm_in):].set(a_scat_1_out[t, (N_scat_2 - (N_ch - N_ch_slm_in)):])\n",
        "\n",
        "    b_total_in = jnp.array([jnp.kron(b_slm_in[t], b_scat2_in[t]) for t in range(t_steps)])\n",
        "    U_multi_channel_slm = construct_U_multi_channel_slm(N_slm, phase_mod, amp_mod, t_steps)\n",
        "    I2_prime = construct_I_prime(N_scat_2, delta, t_steps)\n",
        "    U_tensor_product_stage_2 = jnp.array([jnp.kron(U_multi_channel_slm[t], I2_prime[t]) for t in range(t_steps)])\n",
        "    b_total_out = jnp.array([jnp.dot(U_tensor_product_stage_2[t], b_total_in[t]) for t in range(t_steps)])\n",
        "\n",
        "    b_total_out_reshaped = b_total_out.reshape(t_steps, N_slm, N_scat_2)\n",
        "    b_slm_out = jnp.sum(b_total_out_reshaped, axis=-1)\n",
        "\n",
        "    # Compute the total E-field on the atom plane\n",
        "    E_field_profiles = compute_total_E_field_profile(X, Y, b_slm_out, beam_centers, beam_waist)\n",
        "\n",
        "    # Extract E-fields at the atom positions\n",
        "    E_fields_at_atoms = extract_E_field_at_atoms(E_field_profiles, atom_positions, X, Y)\n",
        "\n",
        "    # Compute interaction strength α(t) for each atom\n",
        "    alpha_t = compute_alpha_t(E_fields_at_atoms, dipoles, Omega_prefactor_MHz)\n",
        "\n",
        "    # g_real_t and g_imag_t represent g(t) in the Jaynes-Cummings model, g(t) = eff_Rabi(t)/2\n",
        "    g_real_t = alpha_t.real / 2\n",
        "    g_imag_t = alpha_t.imag / 2\n",
        "\n",
        "    # Construct the time-dependent Hamiltonian\n",
        "    H_t = construct_H_time(N_a, N_qubit_level, omega_0, omega_r, g_real_t, g_imag_t, atom_positions, gate_type)\n",
        "\n",
        "    # Evolve the unitary matrix (propagator)\n",
        "    U_t_all = compute_accumulated_propagator(H_t, dt, N_a, N_qubit_level)\n",
        "\n",
        "    # Trace out the field from the final unitary matrix\n",
        "    U_t_traced = trace_out_field_from_unitary(U_t_all[-1], N_a, N_qubit_level)\n",
        "    U_t_traced_all = trace_out_field_from_unitary_t_all(U_t_all, N_a, N_qubit_level)\n",
        "\n",
        "    # Compute fidelity with the target gate\n",
        "    fidelity = compute_fidelity_unitary(U_t_traced, U_target)\n",
        "    fidelity_all = compute_fidelity_unitary_t_all(U_t_traced_all, U_target)\n",
        "\n",
        "    return fidelity_all\n",
        "\n",
        "# ========================================\n",
        "# Part 4: Program Instruction function\n",
        "# ========================================\n",
        "def program_instruction(N_a, key_number, gate_type='single', selected_atoms=None, control_atom=None, target_atom=None):\n",
        "    \"\"\"\n",
        "    Constructs the target gates for selected atoms. If `gate_type` is 'single', it applies single-qubit gates.\n",
        "    Logs the gate applied to each atom.\n",
        "    \"\"\"\n",
        "    if gate_type == 'single':\n",
        "        # Define the Clifford gates for single-qubit gates\n",
        "        clifford_t_gates = clifford_group_and_t_gate()\n",
        "        U_target_multi_qubit = []\n",
        "        key = jrandom.PRNGKey(key_number)  # Initialize the random key for gate selection\n",
        "\n",
        "        # Apply random single-qubit gates to selected atoms\n",
        "        for atom_idx in range(N_a):\n",
        "            if selected_atoms is None or atom_idx in selected_atoms:\n",
        "                key, subkey = jrandom.split(key)  # Split key for each atom to ensure different gates\n",
        "                gate_idx = jrandom.randint(subkey, (), minval=0, maxval=len(clifford_t_gates))\n",
        "                gate_name, gate = clifford_t_gates[gate_idx]\n",
        "                logger.info(f\"Applying {gate_name} gate to Atom {atom_idx}\")\n",
        "                U_target_multi_qubit.append(gate)\n",
        "            else:\n",
        "                logger.info(f\"Applying Identity gate to Atom {atom_idx}\")\n",
        "                U_target_multi_qubit.append(jnp.eye(2))  # Identity gate for unselected atoms\n",
        "\n",
        "        # Combine the gates using the Kronecker product\n",
        "        U_target = U_target_multi_qubit[0]\n",
        "        for gate in U_target_multi_qubit[1:]:\n",
        "            U_target = jnp.kron(U_target, gate)\n",
        "\n",
        "        return U_target\n",
        "\n",
        "\n",
        "# ========================================\n",
        "# Part 5: Modified Custom Gymnasium Environment with Warm-Up Start\n",
        "# ========================================\n",
        "\n",
        "class QOCEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    Custom Environment for Quantum Optimal Control using Gymnasium interface.\n",
        "    Enhanced with warm-up start for better initial performance.\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(QOCEnv, self).__init__()\n",
        "\n",
        "        # Store the entire config for access in other methods\n",
        "        self.config = config\n",
        "\n",
        "        # Configuration parameters\n",
        "        self.t_steps = self.config.get('t_steps', 500)\n",
        "        self.N_ch = self.config.get('N_ch', 6)\n",
        "        self.N_a = self.config.get('N_a', 3)\n",
        "        self.U_target = self.config.get('system_params', {}).get('U_target')\n",
        "\n",
        "        if self.U_target is None:\n",
        "            raise ValueError(\"U_target is not defined in the configuration.\")\n",
        "\n",
        "        # Control voltage parameters\n",
        "        self.piecewise_segments = self.config.get('piecewise_segments', 50)\n",
        "        self.min_voltage = self.config.get('min_voltage', -15.0)\n",
        "        self.max_voltage = self.config.get('max_voltage', 15.0)\n",
        "        self.max_delta_voltage = self.config.get('max_delta_voltage', 1.0)\n",
        "\n",
        "        # History parameters\n",
        "        self.history_length = self.config.get('history_length', 5)\n",
        "\n",
        "        # Define action and observation space\n",
        "        self.action_space = spaces.Box(\n",
        "            low=-1.0,\n",
        "            high=1.0,\n",
        "            shape=(self.N_ch,),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "        # Observation space\n",
        "        obs_shape = (self.history_length, self.N_ch, self.piecewise_segments + 2)\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=np.full(obs_shape, self.min_voltage, dtype=np.float32),\n",
        "            high=np.full(obs_shape, self.max_voltage, dtype=np.float32),\n",
        "            shape=obs_shape,\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "        # Initialize variables\n",
        "        self.current_step = 0\n",
        "        self.done = False\n",
        "        self.fidelity = 0.0\n",
        "        self.max_steps = self.config.get('max_steps', 100)\n",
        "\n",
        "        # Track best fidelity and corresponding voltage\n",
        "        self.best_fidelity = 0.0\n",
        "        self.best_voltage = np.zeros((self.N_ch, self.piecewise_segments), dtype=np.float32)\n",
        "\n",
        "        # Store system parameters\n",
        "        self.system_params = self.config.get('system_params', {})\n",
        "        self.APIC_params = self.config.get('APIC_params', {})\n",
        "        self.atom_beam_params = self.config.get('atom_beam_params', {})\n",
        "        self.control_Vt_params = self.config.get('control_Vt_params', {})\n",
        "\n",
        "        # Initialize voltage levels\n",
        "        self.current_voltage = self.np_random.uniform(\n",
        "            low=self.min_voltage,\n",
        "            high=self.max_voltage,\n",
        "            size=(self.N_ch, self.piecewise_segments)\n",
        "        ).astype(np.float32)\n",
        "\n",
        "        # Initialize history buffer\n",
        "        self.voltage_history = deque(maxlen=self.history_length)\n",
        "        fidelity_array = np.full((self.N_ch, 1), self.fidelity, dtype=np.float32)\n",
        "        self.current_segment = 0\n",
        "        segment_array = np.full((self.N_ch, 1), self.current_segment, dtype=np.float32)\n",
        "        initial_observation = np.hstack((self.current_voltage, fidelity_array, segment_array))\n",
        "        for _ in range(self.history_length):\n",
        "            self.voltage_history.append(initial_observation.copy())\n",
        "\n",
        "        # Initialize logging\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "        # Initialize random number generator\n",
        "        self.seed()\n",
        "\n",
        "        # Extract scaling methods from config\n",
        "        self.scaling_methods = self.config.get('reward_scaling_params', {}).get('scaling_methods', [\n",
        "            {'method': 'linear', 'min_ratio': 0.0, 'max_ratio': 0.6},\n",
        "            {'method': 'quadratic', 'min_ratio': 0.6, 'max_ratio': 0.9},\n",
        "            {'method': 'exponential', 'min_ratio': 0.9, 'max_ratio': 1.0},\n",
        "        ])\n",
        "\n",
        "        # Extract target fidelity\n",
        "        self.target_fidelity = self.config.get('target_fidelity', 0.999)\n",
        "\n",
        "        # Define other reward scaling parameters\n",
        "        self.a = self.config.get('reward_scaling_params', {}).get('a', 1.0)  # Scaling factor for absolute fidelity\n",
        "        self.b = self.config.get('reward_scaling_params', {}).get('b', 1.0)  # Scaling factor for fidelity improvement\n",
        "        self.method = 'linear'  # Initial scaling method\n",
        "        self.k = self.config.get('reward_scaling_params', {}).get('k', 5.0)  # Relevant for exponential scaling\n",
        "        self.thresholds = self.config.get('reward_scaling_params', {}).get('thresholds', [0.8, 0.9])  # Fidelity thresholds for bonuses\n",
        "        self.bonus = self.config.get('reward_scaling_params', {}).get('bonus', 5.0)  # Bonus reward for crossing thresholds\n",
        "        self.clip_min = self.config.get('reward_scaling_params', {}).get('clip_min', -10.0)  # Minimum reward\n",
        "        self.clip_max = self.config.get('reward_scaling_params', {}).get('clip_max', 10.0)  # Maximum reward\n",
        "        self.step_penalty = self.config.get('reward_scaling_params', {}).get('step_penalty', 0.01)  # Penalty per step\n",
        "\n",
        "    def seed(self, seed: Optional[int] = None):\n",
        "        \"\"\"\n",
        "        Set the seed for this environment's random number generator(s).\n",
        "        \"\"\"\n",
        "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def select_scaling_method(self, best_fidelity):\n",
        "        \"\"\"\n",
        "        Selects the scaling method based on the progress towards the target fidelity.\n",
        "        \"\"\"\n",
        "        ratio = best_fidelity / self.target_fidelity\n",
        "        new_method = None\n",
        "\n",
        "        for scaling in self.scaling_methods:\n",
        "            if scaling['min_ratio'] <= ratio < scaling['max_ratio']:\n",
        "                new_method = scaling['method']\n",
        "                break\n",
        "\n",
        "        # If ratio exceeds the highest threshold\n",
        "        if new_method is None and ratio >= self.scaling_methods[-1]['max_ratio']:\n",
        "            new_method = self.scaling_methods[-1]['method']\n",
        "\n",
        "        if new_method and new_method != self.method:\n",
        "            self.logger.info(\n",
        "                f\"Scaling method changed from {self.method} to {new_method} based on best fidelity ratio {ratio:.2f}.\"\n",
        "            )\n",
        "            self.method = new_method\n",
        "\n",
        "    def compute_scaled_reward(self, final_fidelity, improvement):\n",
        "        \"\"\"\n",
        "        Computes the scaled reward based on the chosen method, improvement, and threshold bonuses.\n",
        "        \"\"\"\n",
        "        # Select the appropriate scaling method based on current best fidelity\n",
        "        self.select_scaling_method(self.best_fidelity)\n",
        "\n",
        "        # Scale raw fidelity based on the chosen method\n",
        "        if self.method == 'linear':\n",
        "            scaled_fidelity = self.a * final_fidelity\n",
        "        elif self.method == 'quadratic':\n",
        "            scaled_fidelity = self.a * (final_fidelity ** 2)\n",
        "        elif self.method == 'exponential':\n",
        "            scaled_fidelity = self.a * (math.exp(self.k * final_fidelity) - 1)\n",
        "        elif self.method == 'log':\n",
        "            scaled_fidelity = self.a * (math.log(self.k * final_fidelity) - 1)\n",
        "        elif self.method == 'sigmoid':\n",
        "            # Sigmoid scaling: reward increases sharply around a central fidelity ratio\n",
        "            c = 0.95  # Central point where sigmoid is steepest (adjust as needed)\n",
        "            scaled_fidelity = self.a * (1 / (1 + math.exp(-self.k * (final_fidelity - c))))\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported scaling method\")\n",
        "\n",
        "        # Add improvement reward\n",
        "        if improvement > 0:\n",
        "            scaled_fidelity += self.b * improvement\n",
        "\n",
        "        # Add threshold bonuses\n",
        "        threshold_bonus = 0.0\n",
        "        for threshold in self.thresholds:\n",
        "            # Make thresholds relative to target fidelity\n",
        "            relative_threshold = threshold * self.target_fidelity\n",
        "            if self.best_fidelity < relative_threshold <= final_fidelity:\n",
        "                threshold_bonus += self.bonus\n",
        "        scaled_fidelity += threshold_bonus\n",
        "\n",
        "        return scaled_fidelity\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Apply an action (voltage adjustments for the current segment),\n",
        "        compute fidelity, and return the observation, reward, terminated, truncated, and info.\n",
        "        Implements enhanced reward design with adaptive and hybrid scaling.\n",
        "        \"\"\"\n",
        "        if self.done:\n",
        "            raise ValueError(\"Episode has ended. Call reset() to start a new episode.\")\n",
        "\n",
        "        # Clip the action to ensure it's within [-1, 1]\n",
        "        action = np.clip(action, -1.0, 1.0)\n",
        "\n",
        "        # Scale actions to the desired delta voltage range\n",
        "        scaled_action = action * self.max_delta_voltage  # Adjusted to max_delta_voltage\n",
        "\n",
        "        # Apply delta V to the current segment\n",
        "        self.current_voltage[:, self.current_segment] += scaled_action\n",
        "        self.current_voltage[:, self.current_segment] = np.clip(\n",
        "            self.current_voltage[:, self.current_segment],\n",
        "            self.min_voltage,\n",
        "            self.max_voltage\n",
        "        )\n",
        "\n",
        "        # Compute fidelity up to the current segment\n",
        "        V0_t_list = jnp.array(self.current_voltage[:, :self.current_segment + 1])\n",
        "        V1_t_list = jnp.array(self.current_voltage[:, :self.current_segment + 1])\n",
        "\n",
        "        fidelity_all = compute_multi_qubit_fidelity_closed_system(\n",
        "            V0_t_list, V1_t_list,\n",
        "            self.APIC_params.get('L'), self.APIC_params.get('n0'),\n",
        "            self.APIC_params.get('lambda_0'), self.APIC_params.get('a0'), self.APIC_params.get('t0'),\n",
        "            self.APIC_params.get('a1'), self.APIC_params.get('t1'), self.APIC_params.get('phase_mod'),\n",
        "            self.APIC_params.get('amp_mod'), self.system_params.get('delta'),\n",
        "            self.atom_beam_params.get('atom_positions'), self.atom_beam_params.get('dipoles'),\n",
        "            self.atom_beam_params.get('beam_centers'), self.atom_beam_params.get('beam_waist'),\n",
        "            self.atom_beam_params.get('X'), self.atom_beam_params.get('Y'), self.atom_beam_params.get('Omega_prefactor_MHz'),\n",
        "            self.control_Vt_params.get('t_steps'), self.control_Vt_params.get('dt'),\n",
        "            self.system_params.get('N_ch'), self.system_params.get('distances'), self.system_params.get('coupling_lengths'),\n",
        "            self.system_params.get('n_eff_list'), self.system_params.get('kappa0'), self.system_params.get('alpha'),\n",
        "            self.system_params.get('enable_crosstalk'),\n",
        "            self.system_params.get('N_slm'), self.system_params.get('N_ch_slm_in'), self.system_params.get('N_scat_1'),\n",
        "            self.system_params.get('N_scat_2'), self.system_params.get('N_a'),\n",
        "            self.system_params.get('N_qubit_level'), self.system_params.get('omega_0'),\n",
        "            self.system_params.get('omega_r'), self.system_params.get('a_pic'),\n",
        "            self.system_params.get('a_scat_1'),\n",
        "            self.U_target, self.system_params.get('gate_type')\n",
        "        )\n",
        "\n",
        "        # Get unclipped fidelity\n",
        "        try:\n",
        "            unclipped_fidelity = float(jnp.real(fidelity_all[-1]))\n",
        "        except (IndexError, TypeError) as e:\n",
        "            self.logger.error(f\"Error computing fidelity: {e}\")\n",
        "            unclipped_fidelity = 0.0  # Assign a default value or handle appropriately\n",
        "\n",
        "        # Clip fidelity to [0,1]\n",
        "        final_fidelity = np.clip(unclipped_fidelity, 0.0, 1.0)\n",
        "\n",
        "        # Calculate fidelity improvement\n",
        "        improvement = final_fidelity - self.best_fidelity\n",
        "\n",
        "        # Compute scaled reward\n",
        "        scaled_reward = self.compute_scaled_reward(final_fidelity, improvement)\n",
        "\n",
        "        # Clip the scaled reward\n",
        "        scaled_reward = np.clip(scaled_reward, self.clip_min, self.clip_max)\n",
        "\n",
        "        # Initialize reward\n",
        "        reward = scaled_reward\n",
        "\n",
        "        if unclipped_fidelity > 1.0:\n",
        "            # Reject the action by reverting to the best_voltage\n",
        "            self.current_voltage = self.best_voltage.copy()\n",
        "\n",
        "            # Assign a significant penalty\n",
        "            penalty = -1000.0  # Adjust the penalty value as needed\n",
        "            reward = penalty\n",
        "\n",
        "            # Terminate the episode\n",
        "            self.done = True\n",
        "\n",
        "            # Revert fidelity to best_fidelity\n",
        "            final_fidelity = self.best_fidelity\n",
        "            self.fidelity = final_fidelity\n",
        "        else:\n",
        "            # Update best_fidelity and best_voltage if improvement occurred\n",
        "            if improvement > 0:\n",
        "                self.best_fidelity = final_fidelity\n",
        "                self.best_voltage = self.current_voltage.copy()\n",
        "\n",
        "            # Always update self.fidelity to the latest final_fidelity\n",
        "            self.fidelity = final_fidelity\n",
        "\n",
        "        # Advance to next segment\n",
        "        self.current_segment += 1\n",
        "        if self.current_segment >= self.piecewise_segments:\n",
        "            self.done = True  # Terminate episode after all segments are controlled\n",
        "\n",
        "        # Initialize info dict with the correct final_fidelity\n",
        "        info = {\n",
        "            'final_fidelity': final_fidelity,  # Updated to reflect current step's fidelity\n",
        "            'current_step': self.current_step,\n",
        "            'current_segment': self.current_segment\n",
        "        }\n",
        "\n",
        "        # Include best_voltage in info if updated\n",
        "        if improvement > 0:\n",
        "            info['best_voltage'] = self.best_voltage.copy()\n",
        "\n",
        "        # Update history buffer\n",
        "        fidelity_array = np.full((self.N_ch, 1), self.fidelity, dtype=np.float32)\n",
        "        segment_array = np.full((self.N_ch, 1), self.current_segment, dtype=np.float32)\n",
        "        observation_component = np.hstack((self.current_voltage, fidelity_array, segment_array))\n",
        "        self.voltage_history.append(observation_component.copy())\n",
        "\n",
        "        # Stack the history into the observation\n",
        "        observation = np.stack(self.voltage_history, axis=0)\n",
        "\n",
        "        # Determine 'terminated' and 'truncated'\n",
        "        terminated = False  # Define additional termination conditions if any\n",
        "        truncated = self.done  # Episode truncated due to step limit or target achieved\n",
        "\n",
        "        # Enhanced Logging: Detailed debug information\n",
        "        self.logger.debug(f\"Segment: {self.current_segment}, Reward: {reward:.4f}, Fidelity: {self.fidelity:.4f}, Done: {self.done}\")\n",
        "\n",
        "        return observation.astype(np.float32), reward, terminated, truncated, info\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        \"\"\"\n",
        "        Render the environment to the screen.\n",
        "        \"\"\"\n",
        "        if mode == 'human':\n",
        "            print(f\"Segment: {self.current_segment} | Fidelity: {self.fidelity:.4f}\")\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"\n",
        "        Clean up resources.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):\n",
        "        try:\n",
        "            super().reset(seed=seed)\n",
        "            self.current_step = 0\n",
        "            self.done = False\n",
        "            self.fidelity = 0.0\n",
        "            self.best_fidelity = 0.0\n",
        "            self.best_voltage = np.zeros((self.N_ch, self.piecewise_segments), dtype=np.float32)\n",
        "\n",
        "            # **Warm-Up Initialization: Initialize voltages to zero or small random values around zero**\n",
        "            self.current_voltage = self.np_random.normal(\n",
        "                loc=0.0,  # Mean voltage\n",
        "                scale=1.0,  # Small standard deviation to introduce slight variations\n",
        "                size=(self.N_ch, self.piecewise_segments)\n",
        "            ).astype(np.float32)\n",
        "            self.current_voltage = np.clip(\n",
        "                self.current_voltage,\n",
        "                self.min_voltage,\n",
        "                self.max_voltage\n",
        "            )\n",
        "\n",
        "            # **Optional: Fix the first few segments to zero for smoother starts**\n",
        "            fixed_segments = 5  # Number of initial segments to fix\n",
        "            self.current_voltage[:, :fixed_segments] = 0.0  # Or another heuristic initial voltage\n",
        "\n",
        "            # Initialize history buffer\n",
        "            self.voltage_history = deque(maxlen=self.history_length)\n",
        "            fidelity_array = np.full((self.N_ch, 1), self.fidelity, dtype=np.float32)\n",
        "            self.current_segment = 0  # Reset to first segment\n",
        "            segment_array = np.full((self.N_ch, 1), self.current_segment, dtype=np.float32)\n",
        "            initial_observation = np.hstack((self.current_voltage, fidelity_array, segment_array))\n",
        "            for _ in range(self.history_length):\n",
        "                self.voltage_history.append(initial_observation.copy())\n",
        "\n",
        "            # Stack the history into the observation\n",
        "            observation = np.stack(self.voltage_history, axis=0)\n",
        "            return observation.astype(np.float32), {}\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error during reset: {e}\")\n",
        "            raise e  # Re-raise to notify the worker\n",
        "\n",
        "# ========================================\n",
        "# Part 6: Modified Configuration Setup\n",
        "# ========================================\n",
        "\n",
        "def create_config(simple=False):\n",
        "    # Define APIC parameters\n",
        "    APIC_params = {\n",
        "        'L': 600 * 780e-9 / 1.95,  # Example calculation based on your main code\n",
        "        'n0': 1.95,\n",
        "        'lambda_0': 780e-9,\n",
        "        'a0': 0.998,\n",
        "        't0': 0.998,\n",
        "        'a1': 0.998,\n",
        "        't1': 0.998,\n",
        "        'phase_mod': jnp.zeros(6),  # Assuming N_slm = 6\n",
        "        'amp_mod': jnp.ones(6)      # Assuming N_slm = 6\n",
        "    }\n",
        "\n",
        "    # Define atom beam parameters\n",
        "    X, Y = generate_grid(grid_size=600, grid_range=(-6, 6))\n",
        "    atom_positions = generate_atom_positions_equilateral(3, side_length=3.0, center=(0, 0))  # N_a = 3\n",
        "    dipoles = generate_dipoles(3)  # N_a = 3\n",
        "    beam_centers = atom_positions\n",
        "    beam_waist = 2.0  # µm\n",
        "    Omega_prefactor_MHz = calculate_Omega_rabi_prefactor(20, 1000)  # I_mW_per_cm2=20, Detuning_MHz=1000\n",
        "    a_pic = jnp.array([1.0] * 6)      # N_ch = 6\n",
        "    a_scat_1 = jnp.array([1.0] * 4)   # N_scat_1 = 4\n",
        "\n",
        "    atom_beam_params = {\n",
        "        'atom_positions': atom_positions,\n",
        "        'dipoles': dipoles,\n",
        "        'beam_centers': beam_centers,\n",
        "        'beam_waist': beam_waist,\n",
        "        'X': X,\n",
        "        'Y': Y,\n",
        "        'Omega_prefactor_MHz': Omega_prefactor_MHz,\n",
        "    }\n",
        "\n",
        "    # Define control voltage parameters\n",
        "    t_steps = 100  # Increased from 100 to allow finer control\n",
        "    tmax_fixed = 0.1  # Fixed tmax in microseconds\n",
        "    dt = tmax_fixed / t_steps\n",
        "    control_Vt_params = {\n",
        "        'tmin': 0.0,\n",
        "        'tmax': tmax_fixed,\n",
        "        't_steps': t_steps,\n",
        "        'dt': dt,\n",
        "        'min_V_level': -15.0,\n",
        "        'max_V_level': 15.0\n",
        "    }\n",
        "\n",
        "    # Define system parameters\n",
        "    system_params = {\n",
        "        'a_pic': a_pic,\n",
        "        'a_scat_1': a_scat_1,\n",
        "        'delta': 0.001,\n",
        "        'N_ch': 6,\n",
        "        'distances': generate_distances(6, 1.0, random_variation=0.1, seed=42),\n",
        "        'coupling_lengths': generate_coupling_lengths(6, 600.0, scaling_factor=1.1, random_variation=60.0, seed=42),\n",
        "        'n_eff_list': generate_n_eff_list(6, 1.75, random_variation=0.05, seed=42),\n",
        "        'kappa0': 10.145,\n",
        "        'alpha': 6.934,\n",
        "        'enable_crosstalk': True,\n",
        "        'N_slm': 6,\n",
        "        'N_ch_slm_in': 4,\n",
        "        'N_scat_1': 4,\n",
        "        'N_scat_2': 6 + 4 - 6,  # N_total - N_slm\n",
        "        'N_a': 3,\n",
        "        'N_qubit_level': 2,\n",
        "        'omega_0': 6.835e3,  # MHz\n",
        "        'omega_r': 6.835e3,  # MHz\n",
        "        'a_pic': a_pic,\n",
        "        'a_scat_1': a_scat_1,\n",
        "        'gate_type': 'single'\n",
        "    }\n",
        "\n",
        "    # Generate the target unitary\n",
        "    selected_atoms = [0, 1, 2]  # Set to [0, 1, 2] as per N_a = 3\n",
        "    system_params['U_target'] = program_instruction(\n",
        "        N_a=3,\n",
        "        key_number=12,\n",
        "        gate_type='single',\n",
        "        selected_atoms=selected_atoms\n",
        "    )\n",
        "\n",
        "    # Defensive check to ensure U_target is not None\n",
        "    if system_params['U_target'] is None:\n",
        "        raise ValueError(\"U_target was not correctly assigned by program_instruction.\")\n",
        "\n",
        "    # Define reward scaling parameters with hybrid scaling methods\n",
        "    reward_scaling_params = {\n",
        "        'a': 1.0,  # Scaling factor for absolute fidelity\n",
        "        'b': 1.0,  # Scaling factor for fidelity improvement\n",
        "        'scaling_methods': [  # Define scaling methods with relative thresholds\n",
        "            {'method': 'log', 'min_ratio': 0.0, 'max_ratio': 0.5},\n",
        "            {'method': 'linear', 'min_ratio': 0.5, 'max_ratio': 0.9},\n",
        "            {'method': 'quadratic', 'min_ratio': 0.9, 'max_ratio': 1.0},\n",
        "        ],\n",
        "        'k': 5.0,  # Relevant for exponential scaling\n",
        "        'thresholds': [0.8, 0.9],  # Fidelity thresholds for bonuses (can also be made relative)\n",
        "        'bonus': 5.0,  # Bonus reward for crossing thresholds\n",
        "        'clip_min': -10.0,  # Minimum reward\n",
        "        'clip_max': 10.0,  # Maximum reward\n",
        "        'step_penalty': 0.01  # Penalty per step\n",
        "    }\n",
        "\n",
        "    config = {\n",
        "        't_steps': t_steps,\n",
        "        'N_ch': 6,\n",
        "        'N_a': 3,\n",
        "        'piecewise_segments': 50,  # Number of voltage segments\n",
        "        'min_voltage': -15.0,\n",
        "        'max_voltage': 15.0,\n",
        "        'history_length': 5,  # Number of past states to include\n",
        "        'max_delta_voltage': 1.0,  # Added parameter for action scaling\n",
        "        'APIC_params': APIC_params,          # Unchanged\n",
        "        'system_params': system_params,      # Only system-related parameters\n",
        "        'atom_beam_params': atom_beam_params,\n",
        "        'control_Vt_params': control_Vt_params,\n",
        "        'reward_scaling_params': reward_scaling_params,  # Updated reward scaling parameters\n",
        "        'stagnant_threshold': 10,           # Number of stagnant episodes before termination\n",
        "        'stagnant_fidelity_min': 0.99,      # Minimum fidelity to consider stagnation\n",
        "        'target_fidelity': 0.999            # Desired fidelity threshold to achieve\n",
        "    }\n",
        "\n",
        "    return config\n",
        "\n",
        "# ========================================\n",
        "# Part 7: Define the Custom Policy\n",
        "# ========================================\n",
        "\n",
        "class CorrelationFeatureExtractor(nn.Module):\n",
        "    \"\"\"\n",
        "    Custom feature extractor using convolutional layers to capture spatial and temporal correlations.\n",
        "    \"\"\"\n",
        "    def __init__(self, observation_space: gym.Space, *, features_dim: int = 256):\n",
        "        \"\"\"\n",
        "        Initializes the feature extractor.\n",
        "\n",
        "        Parameters:\n",
        "        - observation_space (gym.Space): The observation space of the environment.\n",
        "        - features_dim (int): The dimension of the extracted features.\n",
        "        \"\"\"\n",
        "        super(CorrelationFeatureExtractor, self).__init__()\n",
        "\n",
        "        # Validate observation space\n",
        "        assert isinstance(observation_space, spaces.Box), \"Observation space must be of type Box\"\n",
        "        obs_shape = observation_space.shape  # Expected shape: (history_length, N_ch, piecewise_segments + 2)\n",
        "        history_length, N_ch, piecewise_segments_plus_2 = obs_shape\n",
        "\n",
        "        # Define convolutional layers\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=history_length, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "\n",
        "        # Compute the size of the flattened features\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros(1, history_length, N_ch, piecewise_segments_plus_2)\n",
        "            conv_output = self.conv_layers(dummy_input)\n",
        "            conv_output_size = conv_output.shape[1]\n",
        "\n",
        "        # Define fully connected layer\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(conv_output_size, features_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # **Important:** Set the features_dim attribute for SB3\n",
        "        self.features_dim = features_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass for the feature extractor.\n",
        "\n",
        "        Parameters:\n",
        "        - x (torch.Tensor): Tensor of shape (batch_size, history_length, N_ch, piecewise_segments + 2)\n",
        "\n",
        "        Returns:\n",
        "        - torch.Tensor: Extracted features of shape (batch_size, features_dim)\n",
        "        \"\"\"\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class CustomActorCriticPolicy(ActorCriticPolicy):\n",
        "    \"\"\"\n",
        "    Custom Actor-Critic Policy with convolutional feature extractor to capture correlations.\n",
        "    \"\"\"\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        \"\"\"\n",
        "        Initializes the custom policy.\n",
        "\n",
        "        Parameters:\n",
        "        - *args, **kwargs: Arguments and keyword arguments passed to the parent class.\n",
        "        \"\"\"\n",
        "        super(CustomActorCriticPolicy, self).__init__(\n",
        "            *args,\n",
        "            **kwargs,\n",
        "            features_extractor_class=CorrelationFeatureExtractor,\n",
        "            features_extractor_kwargs=dict(features_dim=256),\n",
        "            net_arch=[256, 256, 256],  # Define network architecture for actor and critic\n",
        "            activation_fn=nn.ReLU\n",
        "        )\n",
        "\n",
        "    def forward(self, obs, deterministic=False):\n",
        "        \"\"\"\n",
        "        Forward pass to get actions, values, and log probabilities.\n",
        "\n",
        "        Parameters:\n",
        "        - obs (torch.Tensor): Observation tensor.\n",
        "        - deterministic (bool): Whether to sample actions deterministically.\n",
        "\n",
        "        Returns:\n",
        "        - actions (torch.Tensor): Action tensor.\n",
        "        - values (torch.Tensor): Value estimates.\n",
        "        - log_probs (torch.Tensor): Log probabilities of actions.\n",
        "        \"\"\"\n",
        "        actions, values, log_probs = super().forward(obs, deterministic=deterministic)\n",
        "        return actions, values, log_probs  # Correct order\n",
        "\n",
        "# ========================================\n",
        "# Part 8: Modified Custom Callback\n",
        "# ========================================\n",
        "\n",
        "class RLLoggingCallback(BaseCallback):\n",
        "    \"\"\"\n",
        "    Custom callback for logging additional metrics during training.\n",
        "    Logs to both console and TensorBoard.\n",
        "    Implements early termination if best_fidelity is stuck between stagnant_fidelity_min and target_fidelity for too many episodes.\n",
        "    Also saves the final optimal V(t) and plots upon termination.\n",
        "    \"\"\"\n",
        "    def __init__(self, stagnant_threshold=100,\n",
        "                 stagnant_fidelity_min=0.99,\n",
        "                 target_fidelity=0.999,\n",
        "                 results_dir='results',\n",
        "                 verbose=0):\n",
        "        \"\"\"\n",
        "        Initializes the callback.\n",
        "\n",
        "        Parameters:\n",
        "        - stagnant_threshold (int): Number of consecutive stagnant episodes before terminating training.\n",
        "        - stagnant_fidelity_min (float): Minimum fidelity to consider stagnation.\n",
        "        - target_fidelity (float): Desired fidelity threshold to achieve.\n",
        "        - results_dir (str): Directory where results will be saved.\n",
        "        - verbose (int): Verbosity level.\n",
        "        \"\"\"\n",
        "        super(RLLoggingCallback, self).__init__(verbose)\n",
        "        self.best_fidelity = 0.0\n",
        "        self.best_voltage = None  # To store the best voltage\n",
        "        self.best_fidelity_history = []  # Track best fidelity per episode\n",
        "        self.episode_count = 0\n",
        "        self.stagnant_counter = 0\n",
        "        self.stagnant_threshold = stagnant_threshold\n",
        "        self.stagnant_fidelity_min = stagnant_fidelity_min\n",
        "        self.target_fidelity = target_fidelity\n",
        "        self.start_time = time.time()\n",
        "        self.results_dir = results_dir\n",
        "\n",
        "        # Create the results directory if it doesn't exist\n",
        "        os.makedirs(self.results_dir, exist_ok=True)\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        # Access the current episode's info\n",
        "        infos = self.locals.get('infos', [])\n",
        "        improved = False  # Flag to check if any env improved best_fidelity\n",
        "        new_best_voltage = None  # To store the new best_voltage if any\n",
        "\n",
        "        # Track the maximum fidelity achieved in this step across all envs\n",
        "        max_fidelity_this_step = self.best_fidelity\n",
        "\n",
        "        for env_id, info in enumerate(infos):\n",
        "            if 'final_fidelity' in info:\n",
        "                fidelity = info['final_fidelity']\n",
        "                self.episode_count += 1\n",
        "\n",
        "                # Check if this episode has a new best fidelity\n",
        "                if fidelity > self.best_fidelity:\n",
        "                    self.best_fidelity = fidelity\n",
        "                    self.stagnant_counter = 0\n",
        "                    improved = True\n",
        "                    # Save the corresponding best_voltage\n",
        "                    new_best_voltage = info.get('best_voltage', None)\n",
        "                    if new_best_voltage is not None:\n",
        "                        self.best_voltage = new_best_voltage\n",
        "\n",
        "                    # Log the improvement\n",
        "                    logger.info(\n",
        "                        f\"New best fidelity: {self.best_fidelity:.4f} achieved in Env {env_id} | Episode: {self.episode_count}\"\n",
        "                    )\n",
        "\n",
        "                # Update the maximum fidelity for this step\n",
        "                if fidelity > max_fidelity_this_step:\n",
        "                    max_fidelity_this_step = fidelity\n",
        "\n",
        "        # Append the global best_fidelity to history\n",
        "        self.best_fidelity_history.append(self.best_fidelity)\n",
        "\n",
        "        # After processing all envs in this step\n",
        "        # If no improvement was made in this step\n",
        "        if not improved:\n",
        "            # Check if best_fidelity is within the stagnation range\n",
        "            if self.stagnant_fidelity_min <= self.best_fidelity < self.target_fidelity:\n",
        "                self.stagnant_counter += 1\n",
        "                logger.info(\n",
        "                    f\"Stagnant Counter Incremented: {self.stagnant_counter}/{self.stagnant_threshold} | Best Fidelity: {self.best_fidelity:.4f}\"\n",
        "                )\n",
        "            else:\n",
        "                # Reset the stagnant_counter if best_fidelity is below the min or already reached the target\n",
        "                self.stagnant_counter = 0\n",
        "\n",
        "        # Check for termination based on target fidelity\n",
        "        if self.best_fidelity >= self.target_fidelity:\n",
        "            elapsed_time = time.time() - self.start_time\n",
        "            logger.info(\n",
        "                f\"Target fidelity of {self.best_fidelity:.4f} achieved in {self.episode_count} episodes. \"\n",
        "                f\"Training terminated.\"\n",
        "            )\n",
        "            # Save the best_voltage before terminating\n",
        "            if self.best_voltage is not None:\n",
        "                best_voltage_final_path = os.path.join(self.results_dir, \"best_voltage_final.npy\")\n",
        "                np.save(best_voltage_final_path, self.best_voltage)\n",
        "                logger.info(f\"Final best voltage saved to '{best_voltage_final_path}'.\")\n",
        "\n",
        "\n",
        "            # Save Best Fidelity\n",
        "            best_fidelity_path = os.path.join(self.results_dir, \"best_fidelity.txt\")\n",
        "            with open(best_fidelity_path, \"w\") as f:\n",
        "                f.write(f\"Best Fidelity: {self.best_fidelity:.6f}\\n\")\n",
        "            logger.info(f\"Best fidelity saved to '{best_fidelity_path}'.\")\n",
        "\n",
        "            # Save Best Fidelity History as .npy and .csv\n",
        "            best_fidelity_history_path_npy = os.path.join(self.results_dir, \"best_fidelity_history.npy\")\n",
        "            best_fidelity_history_path_csv = os.path.join(self.results_dir, \"best_fidelity_history.csv\")\n",
        "            np.save(best_fidelity_history_path_npy, np.array(self.best_fidelity_history))\n",
        "            np.savetxt(best_fidelity_history_path_csv, np.array(self.best_fidelity_history), delimiter=\",\", header=\"Episode,Best_Fidelity\")\n",
        "            logger.info(f\"Best fidelity history saved to '{best_fidelity_history_path_npy}' and '{best_fidelity_history_path_csv}'.\")\n",
        "\n",
        "            # Plot Fidelity Progress and Save as .png and .csv\n",
        "            self._plot_fidelity_progress()\n",
        "\n",
        "            return False  # Returning False stops the training\n",
        "\n",
        "        # Check for termination based on stagnation\n",
        "        if self.stagnant_counter >= self.stagnant_threshold:\n",
        "            elapsed_time = time.time() - self.start_time\n",
        "            logger.warning(\n",
        "                f\"Training is stagnating after {self.episode_count} episodes. \"\n",
        "                f\"Best Fidelity: {self.best_fidelity:.4f}. Terminating training.\"\n",
        "            )\n",
        "\n",
        "            # Save the best_voltage before terminating\n",
        "            if self.best_voltage is not None:\n",
        "                best_voltage_final_path = os.path.join(self.results_dir, \"best_voltage_final.npy\")\n",
        "                np.save(best_voltage_final_path, self.best_voltage)\n",
        "                logger.info(f\"Final best voltage saved to '{best_voltage_final_path}'.\")\n",
        "\n",
        "\n",
        "            # Save Best Fidelity\n",
        "            best_fidelity_path = os.path.join(self.results_dir, \"best_fidelity.txt\")\n",
        "            with open(best_fidelity_path, \"w\") as f:\n",
        "                f.write(f\"Best Fidelity: {self.best_fidelity:.6f}\\n\")\n",
        "            logger.info(f\"Best fidelity saved to '{best_fidelity_path}'.\")\n",
        "\n",
        "            # Save Best Fidelity History as .npy and .csv\n",
        "            best_fidelity_history_path_npy = os.path.join(self.results_dir, \"best_fidelity_history.npy\")\n",
        "            best_fidelity_history_path_csv = os.path.join(self.results_dir, \"best_fidelity_history.csv\")\n",
        "            np.save(best_fidelity_history_path_npy, np.array(self.best_fidelity_history))\n",
        "            np.savetxt(best_fidelity_history_path_csv, np.array(self.best_fidelity_history), delimiter=\",\", header=\"Episode,Best_Fidelity\")\n",
        "            logger.info(f\"Best fidelity history saved to '{best_fidelity_history_path_npy}' and '{best_fidelity_history_path_csv}'.\")\n",
        "\n",
        "            # Plot Fidelity Progress and Save as .png and .csv\n",
        "            self._plot_fidelity_progress()\n",
        "\n",
        "            return False  # Returning False stops the training\n",
        "\n",
        "        # Log to console and file\n",
        "        elapsed_time = time.time() - self.start_time\n",
        "        logger.info(\n",
        "            f\"Training Status | Episodes: {self.episode_count} | Best Fidelity: {self.best_fidelity:.4f} | \"\n",
        "            f\"Stagnant Counter: {self.stagnant_counter}/{self.stagnant_threshold} | \"\n",
        "            f\"Elapsed Time: {elapsed_time/60:.2f} min\"\n",
        "        )\n",
        "\n",
        "        return True  # Continue training\n",
        "\n",
        "\n",
        "    def _plot_fidelity_progress(self):\n",
        "        \"\"\"\n",
        "        Plots the global best fidelity vs. episodes and saves it as 'fidelity_progress.png'.\n",
        "        Also saves the fidelity data as 'fidelity_progress.csv'.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            episodes = np.arange(1, len(self.best_fidelity_history) + 1)\n",
        "            best_fidelity = np.array(self.best_fidelity_history)\n",
        "\n",
        "            # Plot fidelity progress\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            plt.plot(episodes, best_fidelity, label='Best Fidelity')\n",
        "            plt.title('Global Best Fidelity Progress Over Episodes')\n",
        "            plt.xlabel('Episode')\n",
        "            plt.ylabel('Best Fidelity')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            plt.tight_layout()\n",
        "            fidelity_plot_path = os.path.join(self.results_dir, \"fidelity_progress.png\")\n",
        "            plt.savefig(fidelity_plot_path)\n",
        "            plt.close()\n",
        "            logger.info(f\"Fidelity progress plot saved as '{fidelity_plot_path}'.\")\n",
        "\n",
        "            # Save fidelity progress data as .csv\n",
        "            fidelity_progress_csv = os.path.join(self.results_dir, \"fidelity_progress.csv\")\n",
        "            df = pd.DataFrame({\n",
        "                'Episode': episodes,\n",
        "                'Best_Fidelity': best_fidelity\n",
        "            })\n",
        "            df.to_csv(fidelity_progress_csv, index=False)\n",
        "            logger.info(f\"Fidelity progress data saved as '{fidelity_progress_csv}'.\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error while plotting or saving fidelity progress: {e}\")\n",
        "\n",
        "# ========================================\n",
        "# Part 9: Modified Environment Creation Function\n",
        "# ========================================\n",
        "def make_env(config, seed):\n",
        "    def _init():\n",
        "        env = QOCEnv(config)\n",
        "        env.seed(seed)\n",
        "        return env\n",
        "    return _init\n",
        "\n",
        "# ========================================\n",
        "# Part 10: Modified Main Function\n",
        "# ========================================\n",
        "def main():\n",
        "    # Define the results directory first to avoid NameError\n",
        "    results_dir = \"results\"\n",
        "    os.makedirs(results_dir, exist_ok=True)  # Create 'results' directory if it doesn't exist\n",
        "\n",
        "    # Configure logging\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    # File handler for logging\n",
        "    log_file = os.path.join(results_dir, \"training_log.txt\")  # Specify the log file name within 'results' directory\n",
        "    file_handler = logging.FileHandler(log_file)\n",
        "    file_handler.setLevel(logging.INFO)\n",
        "    file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "    file_handler.setFormatter(file_formatter)\n",
        "\n",
        "    # Add handlers to the logger\n",
        "    if not logger.handlers:\n",
        "        logger.addHandler(file_handler)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Configure JAX to use multiple threads (cores)\n",
        "    num_envs = 4  # Number of parallel environments; adjust based on your CPU cores\n",
        "    jax.config.update(\"jax_platform_name\", \"cpu\")\n",
        "    os.environ[\"JAX_NUM_THREADS\"] = str(max(1, os.cpu_count() // num_envs))\n",
        "    jax.config.update(\"jax_enable_x64\", True)  # Use float64 for numerical stability\n",
        "\n",
        "    # Create configuration\n",
        "    config = create_config()\n",
        "\n",
        "    # Instantiate multiple environments for parallel training\n",
        "    env_fns = [make_env(config, seed=i) for i in range(num_envs)]\n",
        "    vec_env = SubprocVecEnv(env_fns)\n",
        "\n",
        "    # Optional: Check if the environment follows the Gymnasium API\n",
        "    # (Note: Due to complex parameters, this may raise warnings. Proceed if no critical errors.)\n",
        "    # check_env(vec_env, warn=True)\n",
        "\n",
        "    # Instantiate the PPO agent with enhanced hyperparameters\n",
        "    model = PPO(\n",
        "        CustomActorCriticPolicy,  # Custom policy class defined above\n",
        "        vec_env,\n",
        "        verbose=0,  # Suppress default SB3 logs, using custom callback instead\n",
        "        tensorboard_log=os.path.join(results_dir, \"ppo_qoc_tensorboard/\"),\n",
        "        device='cpu',  # Ensure CPU usage; adjust if using GPU\n",
        "        ent_coef=0.1,  # Increased entropy coefficient for exploration\n",
        "        learning_rate=1e-4,  # Reduced from 3e-4 to 1e-4 for stability\n",
        "        clip_range=0.2,\n",
        "        n_steps=2048,          # Increased from default to 2048\n",
        "        gamma=0.99,\n",
        "        gae_lambda=0.95,\n",
        "        batch_size=64,         # Adjust as needed\n",
        "        max_grad_norm=0.5      # Gradient clipping to prevent explosion\n",
        "    )\n",
        "\n",
        "    # Instantiate the custom callback with the desired stagnation threshold and fidelity parameters\n",
        "    rl_logging_callback = RLLoggingCallback(\n",
        "        stagnant_threshold=config.get('stagnant_threshold', 100),\n",
        "        stagnant_fidelity_min=config.get('stagnant_fidelity_min', 0.99),\n",
        "        target_fidelity=config.get('target_fidelity', 0.999),\n",
        "        results_dir=results_dir  # Ensure all outputs are saved in 'results' directory\n",
        "    )\n",
        "\n",
        "    # Train the agent with increased timesteps\n",
        "    total_timesteps = 10000  # Adjust as needed for your training regimen\n",
        "    logger.info(\"Commencing PPO training...\")\n",
        "    model.learn(total_timesteps=total_timesteps, callback=rl_logging_callback)\n",
        "\n",
        "    # After training, compute and log the total run time in minutes\n",
        "    total_run_time = time.time() - start_time  # Compute total run time in seconds\n",
        "    total_run_time_minutes = total_run_time / 60  # Convert to minutes\n",
        "    logger.info(f\"Total run time: {total_run_time_minutes:.2f} minutes\")  # Log total run time in minutes\n",
        "\n",
        "    # Save the trained model within the 'results' directory\n",
        "    model_save_path = os.path.join(results_dir, \"ppo_qoc_model.zip\")\n",
        "    model.save(model_save_path)\n",
        "    logger.info(f\"Trained PPO model saved as '{model_save_path}'.\")\n",
        "\n",
        "    # Test the trained agent\n",
        "    test_env = DummyVecEnv([make_env(config, seed=100)])\n",
        "    test_model = PPO.load(model_save_path)\n",
        "\n",
        "    # Create a directory to save test results\n",
        "    test_results_dir = os.path.join(results_dir, \"test_results\")\n",
        "    os.makedirs(test_results_dir, exist_ok=True)\n",
        "\n",
        "    for episode in range(1, 6):\n",
        "        obs, _ = test_env.reset()\n",
        "        done = False\n",
        "        total_reward = 0.0\n",
        "        while not done:\n",
        "            action, _states = test_model.predict(obs, deterministic=True)\n",
        "            obs, reward, terminated, truncated, info = test_env.step(action)\n",
        "            done = terminated or truncated\n",
        "            total_reward += reward\n",
        "        logger.info(f\"Test Episode {episode}: Final Fidelity = {total_reward:.4f}\")\n",
        "\n",
        "    # Save the final best_fidelity and best_voltage if not already saved\n",
        "    best_fidelity_path = os.path.join(results_dir, \"best_fidelity.txt\")\n",
        "    best_voltage_final_path = os.path.join(results_dir, \"best_voltage_final.npy\")\n",
        "    if os.path.exists(best_fidelity_path) and os.path.exists(best_voltage_final_path):\n",
        "        logger.info(\"Final best fidelity and voltage have been saved.\")\n",
        "    else:\n",
        "        logger.warning(\"Best fidelity and/or best voltage files are missing.\")\n",
        "\n",
        "    # Optionally, close environments\n",
        "    vec_env.close()\n",
        "    test_env.close()\n",
        "\n",
        "# ========================================\n",
        "# Entry Point\n",
        "# ========================================\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
